{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e92cdf8",
   "metadata": {},
   "source": [
    "# Flow Modell für zweidimensionale Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461468f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:04.702667Z",
     "start_time": "2022-01-28T15:04:02.091110Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "#Kleine Module von Lukas Rinder https://github.com/LukasRinder/normalizing-flows:\n",
    "from LukasRinder.LukasRinder import Made\n",
    "from LukasRinder.LukasRinder import train_density_estimation, nll\n",
    "from LukasRinder.LukasRinder import plot_heatmap_2d\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd3cf8",
   "metadata": {},
   "source": [
    "### Nicht alle Versionen von Tensorflow-Probability sind mit alles Python Versionen kompatibel. Tfp steckt noch in der Beta-Version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59b8b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:04.718668Z",
     "start_time": "2022-01-28T15:04:04.704664Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.__version__, tf.__version__, tfp.__version__, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe6f6d9",
   "metadata": {},
   "source": [
    "# Goethe Daten mit Verwerfungsmethode generieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3eb98a",
   "metadata": {},
   "source": [
    "### Bild des Goethe Universitäts Logos laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37079dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:04.813831Z",
     "start_time": "2022-01-28T15:04:04.719625Z"
    }
   },
   "outputs": [],
   "source": [
    "img = Image.open(\"goethe-kopf.jpg\")\n",
    "img = img.convert(\"1\")\n",
    "img1 = np.asarray(img)\n",
    "epsilon = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f751e2a3",
   "metadata": {},
   "source": [
    "### Zufallszahlen erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900049c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:04.845951Z",
     "start_time": "2022-01-28T15:04:04.816828Z"
    }
   },
   "outputs": [],
   "source": [
    "y_cords = np.random.randint(low=epsilon, high=1497-epsilon, size=1000000)\n",
    "x_cords = np.random.randint(low=epsilon, high=1663-epsilon, size=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c717604",
   "metadata": {},
   "source": [
    "### Nur Daten, die maximal Epsilon Pixel (in Maximumsnorm) Abstand zu farbigen Pixeln des Logos haben, behalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b9bcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:13.711577Z",
     "start_time": "2022-01-28T15:04:04.846848Z"
    }
   },
   "outputs": [],
   "source": [
    "x_data, y_data = [], []\n",
    "for i in range(1000000):\n",
    "    keep = False\n",
    "    for j in range(2*epsilon):\n",
    "        for k in range(2*epsilon):\n",
    "            if img1[y_cords[i]+j-epsilon][x_cords[i]+k-epsilon] == False:\n",
    "                keep = True\n",
    "    if keep == True:\n",
    "        x_data.append(x_cords[i])\n",
    "        y_data.append(y_cords[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030a80c",
   "metadata": {},
   "source": [
    "### Y Koordinaten spiegeln. \n",
    "#### Dies ist nötig, da jpg Dateien ungewöhnliche koordinatenachsen nutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1cf9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:13.791182Z",
     "start_time": "2022-01-28T15:04:13.713284Z"
    }
   },
   "outputs": [],
   "source": [
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "y_data = np.where(y_data > ((1493-epsilon)/2), y_data - 2*(y_data - (1493-epsilon)/2), y_data + 2*((1493-epsilon)/2 - y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed309c",
   "metadata": {},
   "source": [
    "### Alle Daten visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb4e58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:14.091105Z",
     "start_time": "2022-01-28T15:04:13.793181Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_data, y_data, s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4c53e",
   "metadata": {},
   "source": [
    "### Daten auf [0,1]^2 skalieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecbf466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:14.199979Z",
     "start_time": "2022-01-28T15:04:14.093104Z"
    }
   },
   "outputs": [],
   "source": [
    "x_data = np.subtract(x_data, min(x_data)*np.ones(x_data.shape))\n",
    "x_data = x_data/max(x_data)\n",
    "y_data = np.subtract(y_data, min(y_data)*np.ones(y_data.shape))\n",
    "y_data = y_data/max(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78091f8",
   "metadata": {},
   "source": [
    "### Daten konkatenieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57b9b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:14.879193Z",
     "start_time": "2022-01-28T15:04:14.201978Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(x_data)):\n",
    "    data.append(np.array([x_data[i], y_data[i]]))\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011f2a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:14.895399Z",
     "start_time": "2022-01-28T15:04:14.883188Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = tf.cast(data[:200000], tf.float32)\n",
    "x_val = tf.cast(data[200000:300000], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c55374",
   "metadata": {},
   "source": [
    "### Batches initialisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d0704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:14.910783Z",
     "start_time": "2022-01-28T15:04:14.897149Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_s = 128\n",
    "\n",
    "x_train = tf.cast(data[:50000], tf.float32)\n",
    "x_val = tf.cast(data[50000:], tf.float32)\n",
    "batched_train = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000).batch(batch_s)\n",
    "batched_val = tf.data.Dataset.from_tensor_slices(x_val).batch(batch_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f421ff",
   "metadata": {},
   "source": [
    "### Funktion, die ein MAF bzw. IAF Modell erzeugt.\n",
    "#### Die Permutation ist hier fest gewählt und vertauscht die Einträge. Die einzelnen Transformationen werden mit tfb.Chain verkettet. Hier wird das in umgekehrter Reihenfolge getan, sodass die zuerst implementierte Transformation T1 entspricht (auf dem latenten Raum operiert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e3347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:14.926412Z",
     "start_time": "2022-01-28T15:04:14.912808Z"
    }
   },
   "outputs": [],
   "source": [
    "def AutoregressiveFlow_2D(layers, hidden_shape=[64, 64], activation=\"relu\", inverse=False):\n",
    "    base_dist = tfd.MultivariateNormalDiag(loc=tf.zeros(shape=[2], dtype=tf.float32))\n",
    "    bijectors = []\n",
    "    params=0\n",
    "    if inverse:\n",
    "        for i in range(layers):\n",
    "            bijectors.append(tfb.Invert(tfb.MaskedAutoregressiveFlow(\n",
    "                shift_and_log_scale_fn = Made(params=2, hidden_units=hidden_shape, activation=activation))))\n",
    "            bijectors.append(tfb.Permute(permutation=[1, 0]))\n",
    "        bijector = tfb.Chain(bijectors=list(reversed(bijectors)))\n",
    "    else:\n",
    "        for i in range(layers):\n",
    "            bijectors.append(tfb.MaskedAutoregressiveFlow(\n",
    "                shift_and_log_scale_fn = Made(params=2, hidden_units=hidden_shape, activation=activation)))\n",
    "            bijectors.append(tfb.Permute(permutation=[1, 0]))\n",
    "        bijector = tfb.Chain(bijectors=list(reversed(bijectors)))\n",
    "\n",
    "    masked_auto_flow = tfd.TransformedDistribution(distribution=base_dist, bijector=bijector)\n",
    "    masked_auto_flow.log_prob(base_dist.sample())\n",
    "    for theta in masked_auto_flow.trainable_variables:\n",
    "        params += np.prod(theta.shape)\n",
    "    print(\"trainable parameters:\", params)\n",
    "    return masked_auto_flow, base_dist, bijectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d932e",
   "metadata": {},
   "source": [
    "### Parameter festlegen und einen Namen für die Checkpoints festlegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ed32a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:14.942514Z",
     "start_time": "2022-01-28T15:04:14.928090Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = 60\n",
    "base_lr = 1e-3\n",
    "end_lr = 1e-4\n",
    "epochs = 200\n",
    "dataset = \"goethe\"\n",
    "trainsize = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f58f62",
   "metadata": {},
   "source": [
    "### Modell initialisieren. In diesem Stadium entspricht MAF der Startverteilung bzw. full_bijector der Identitätsabbildung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3bb686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.118089Z",
     "start_time": "2022-01-28T15:04:14.944519Z"
    }
   },
   "outputs": [],
   "source": [
    "MAF, base_dist, list_of_bijectors = AutoregressiveFlow_2D(layers, inverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff341f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.134056Z",
     "start_time": "2022-01-28T15:04:15.120046Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(base_lr, epochs, end_lr, power=0.5)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ba4b37",
   "metadata": {},
   "source": [
    "### Checkpoints initialisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64eae5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.150101Z",
     "start_time": "2022-01-28T15:04:15.136049Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_dir = f\"{dataset}/tmp_{layers}\"\n",
    "ckpt_prefix = os.path.join(ckpt_dir, \"ckpt\")\n",
    "\n",
    "ckpt = tf.train.Checkpoint(optimizer=opt, model=MAF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64884bbf",
   "metadata": {},
   "source": [
    "### Funktion, die ein Modell trainiert.\n",
    "#### Dabei werden Trainings- und Validierungsdaten verwendet, um Overfitting festzustellen. Nach dem Durchlaufen aller Epochen, wird die benötigte Zeit ausgegeben. Zudem kann gewählt werden, ob die Dichte während des Trainings visualisiert werden soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1cf5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.166060Z",
     "start_time": "2022-01-28T15:04:15.152099Z"
    }
   },
   "outputs": [],
   "source": [
    "def TrainFlow(flow, batched_train, batched_val, epochs, train_size, optimizer, checkpoint, checkpoint_pref, heat_name=None):\n",
    "\n",
    "    t_losses, v_losses = [], []\n",
    "    t_start = time.time()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        batched_train.shuffle(buffer_size=train_size, reshuffle_each_iteration=True)\n",
    "        batch_t_losses = []\n",
    "        for batch in batched_train:\n",
    "            batch_loss = train_density_estimation(flow, optimizer, batch)\n",
    "            batch_t_losses.append(batch_loss)\n",
    "        t_loss = tf.reduce_mean(batch_t_losses)\n",
    "\n",
    "        batch_v_losses = []\n",
    "        for batch in batched_val:\n",
    "            batch_loss = nll(flow, batch)\n",
    "            batch_v_losses.append(batch_loss)\n",
    "        v_loss = tf.reduce_mean(batch_v_losses)\n",
    "\n",
    "        t_losses.append(t_loss)\n",
    "        v_losses.append(v_loss)\n",
    "        print(f\"Epoch {i+1}: train loss: {t_loss}, val loss: {v_loss}\")\n",
    "        \n",
    "        if i == 0:\n",
    "            min_v_loss = v_loss\n",
    "            best_epoch = 0\n",
    "        if v_loss < min_v_loss:\n",
    "            min_v_loss = v_loss\n",
    "            best_epoch = i\n",
    "            checkpoint.write(file_prefix=checkpoint_pref)\n",
    "            \n",
    "        if heat_name:        \n",
    "            if (i < 12) or (i % 30 == 0):\n",
    "                plot_heatmap_2d(flow, 0.0, 1.0, 0.0, 1.0, mesh_count=500, name=heat_name + str(i+1))\n",
    "                \n",
    "    print(\"train time:\", time.time() - t_start)\n",
    "    \n",
    "    return t_losses, v_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56c03f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:05:48.187304Z",
     "start_time": "2022-01-28T15:05:27.351047Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses = TrainFlow(MAF, batched_train, batched_val, \n",
    "                                     epochs, trainsize, opt, ckpt, ckpt_prefix, heat_name=\"goethe_training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d155fa80",
   "metadata": {},
   "source": [
    "### Plot der Verluste während des Trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234ae13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.981989Z",
     "start_time": "2022-01-28T15:04:15.981989Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_losses)), train_losses, label=\"train loss\")\n",
    "plt.plot(range(len(val_losses)), val_losses, label=\"val loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233bc5a",
   "metadata": {},
   "source": [
    "### Laden des Stadiums des Modelles mit geringstem Verlust auf den Validierungsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c7bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.983978Z",
     "start_time": "2022-01-28T15:04:15.983978Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt.restore(ckpt_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8f00b",
   "metadata": {},
   "source": [
    "### Neue Daten generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582feaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.984967Z",
     "start_time": "2022-01-28T15:04:15.984967Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = MAF.sample(5000).numpy()\n",
    "fig = plt.figure(figsize=(4, 4), dpi=80)\n",
    "plt.scatter(samples[:,0], samples[:,1], s=1)\n",
    "plt.savefig(f\"{layers}_layers_{epochs}_epochs_{dataset}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f79618",
   "metadata": {},
   "source": [
    "### Zwei Funktionen, die zusammen die gesammte Transformation Schrittweise darstellen. \n",
    "#### Immer zwei aufeinander folgende Schritte sind von gleicher Orientierung, dann wird an der Winkelhalbierenden gespiegelt (Permutation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b757e0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.986963Z",
     "start_time": "2022-01-28T15:04:15.986963Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotStep(points, save=False, name=None):\n",
    "    points = points.numpy()\n",
    "    fig = plt.figure(figsize=(4, 4), dpi=80)\n",
    "    plt.scatter(points[:,0], points[:,1], s=1)\n",
    "    if save:\n",
    "        plt.savefig(name+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f379e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.987959Z",
     "start_time": "2022-01-28T15:04:15.987959Z"
    }
   },
   "outputs": [],
   "source": [
    "def FlowSteps(distribution, bijectors_list, samples, steps=\"all\", save=False, name=\"empty\"):\n",
    "    points = distribution.sample(samples)\n",
    "    PlotStep(points, save=save, name=name+\"0\")\n",
    "    last = True\n",
    "\n",
    "    if steps == \"all\":\n",
    "        for bijector in bijectors_list:\n",
    "            points = bijector.forward(points)\n",
    "            PlotStep(points)\n",
    "            last = False\n",
    "\n",
    "    if steps != \"all\":\n",
    "        stepsize = len(bijectors_list) // steps\n",
    "        points = bijectors_list[0].forward(points)\n",
    "        PlotStep(points)\n",
    "        counter = 1\n",
    "        while counter < (len(bijectors_list) - stepsize + 1):\n",
    "            for i in range(stepsize):\n",
    "                points = bijectors_list[counter+i].forward(points)\n",
    "            PlotStep(points, save=save, name=name+str(counter))\n",
    "            counter += stepsize\n",
    "            if counter == len(bijectors_list) - 1:\n",
    "                last = False\n",
    "    if last:\n",
    "        while counter < len(bijectors_list):\n",
    "            points = bijectors_list[counter].forward(points)\n",
    "            counter += 1\n",
    "        PlotStep(points, save=save, name=name+str(len(bijectors_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bedf75a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.989954Z",
     "start_time": "2022-01-28T15:04:15.989954Z"
    }
   },
   "outputs": [],
   "source": [
    "FlowSteps(base_dist, list_of_bijectors, 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc1abf",
   "metadata": {},
   "source": [
    "### Darstellung der erzeugten Dichte des Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e513bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.990952Z",
     "start_time": "2022-01-28T15:04:15.990952Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_heatmap_2d(MAF, 0.0, 1.0, 0.0, 1.0, mesh_count=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006729a8",
   "metadata": {},
   "source": [
    "### Durchschnittlich benötigte Zeit zum Generieren einer Stichprobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f88c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T15:04:15.991950Z",
     "start_time": "2022-01-28T15:04:15.991950Z"
    }
   },
   "outputs": [],
   "source": [
    "time_s = time.time()\n",
    "MAF.sample(2000000)\n",
    "av_sample_time = (time.time() -time_s)/2000000\n",
    "print(av_sample_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
